{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium  \n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "you may not use this file except in compliance with the License.  \n",
    "You may obtain a copy of the License at  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
    "Unless required by applicable law or agreed to in writing, software  \n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "See the License for the specific language governing permissions and  \n",
    "limitations under the License.\n",
    "\n",
    "# MONAI 101 tutorial\n",
    "\n",
    "In this tutorial, we will introduce how simple it can be to run an end-to-end classification pipeline with MONAI.\n",
    "\n",
    "These steps will be included in this tutorial, and each of them will take only a few lines of code:\n",
    "- Dataset download\n",
    "- Data pre-processing\n",
    "- Define a DenseNet-121 and run training\n",
    "- Check the results on test dataset\n",
    "\n",
    "This tutorial will use about 7GB of GPU memory and 10 minutes to run.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/2d_classification/monai_101.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[ignite, tqdm]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.dev2428\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.3.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 2d242d8f1b2876133bcafbe7fa5d967728a74998\n",
      "MONAI __file__: /opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.5.0.post2\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scipy version: 1.14.0\n",
      "Pillow version: 10.4.0\n",
      "Tensorboard version: 2.17.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.18.1\n",
      "tqdm version: 4.66.4\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.2.2\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader\n",
    "from monai.engines import SupervisedTrainer\n",
    "from monai.handlers import StatsHandler\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.networks import eval_mode\n",
    "from monai.networks.nets import densenet121\n",
    "from monai.transforms import LoadImageD, EnsureChannelFirstD, ScaleIntensityD, Compose\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
    "This allows you to save results and reuse downloads.  \n",
    "If not specified a temporary directory will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_directory = \"./MONAI_DATA_DIRECTORY\"\n",
    "os.environ[\"MONAI_DATA_DIRECTORY\"] = fixed_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MONAI_DATA_DIRECTORY\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MONAI transforms to preprocess data\n",
    "\n",
    "Medical images require specialized methods for I/O, preprocessing, and augmentation.\n",
    "They often follow specific formats, are handled with specific protocols, and the data arrays are often high-dimensional.\n",
    "\n",
    "In this example, we will perform image loading, data format verification, and intensity scaling with three `monai.transforms` listed below, and compose a pipeline ready to be used in next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=\"image\", image_only=True),\n",
    "        EnsureChannelFirstD(keys=\"image\"),\n",
    "        ScaleIntensityD(keys=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets using MONAI Apps\n",
    "\n",
    "We use `MedNISTDataset` in MONAI Apps to download a dataset to the specified directory and perform the pre-processing steps in the `monai.transforms` compose.\n",
    "\n",
    "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
    "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
    "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
    "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "If you use the MedNIST dataset, please acknowledge the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-15 20:14:04,839 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2024-07-15 20:14:04,840 - INFO - File exists: MONAI_DATA_DIRECTORY/MedNIST.tar.gz, skipped downloading.\n",
      "2024-07-15 20:14:04,840 - INFO - Non-empty folder exists in MONAI_DATA_DIRECTORY/MedNIST, skipped extracting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 47164/47164 [00:16<00:00, 2887.97it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"training\", download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a network and a supervised trainer\n",
    "\n",
    "To train a model that can perform the classification task, we will use the DenseNet-121 which is known for its performance on the ImageNet dataset.\n",
    "\n",
    "For a typical supervised training workflow, MONAI provides `SupervisedTrainer` to define the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "model = densenet121(spatial_dims=2, in_channels=1, out_channels=6).to(\"cpu\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "trainer = SupervisedTrainer(\n",
    "    device=torch.device(\"cpu\"),\n",
    "    max_epochs=max_epochs,\n",
    "    train_data_loader=DataLoader(dataset, batch_size=512, shuffle=True),\n",
    "    network=model,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-5),\n",
    "    loss_function=torch.nn.CrossEntropyLoss(),\n",
    "    inferer=SimpleInferer(),\n",
    "    train_handlers=StatsHandler(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.SupervisedTrainer:Engine run resuming from iteration 0, epoch 0 until 5 epochs\n",
      "2024-07-15 20:14:36,907 - INFO - Epoch: 1/5, Iter: 1/93 -- label: 2.0000 loss: 1.8574 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/handlers/stats_handler.py:261: UserWarning: ignoring non-scalar output in StatsHandler, make sure `output_transform(engine.state.output)` returns a scalar or dictionary of key and scalar pairs to avoid this warning. image:<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/handlers/stats_handler.py:261: UserWarning: ignoring non-scalar output in StatsHandler, make sure `output_transform(engine.state.output)` returns a scalar or dictionary of key and scalar pairs to avoid this warning. pred:<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-15 20:14:51,823 - INFO - Epoch: 1/5, Iter: 2/93 -- label: 3.0000 loss: 1.8430 \n",
      "2024-07-15 20:15:07,819 - INFO - Epoch: 1/5, Iter: 3/93 -- label: 3.0000 loss: 1.8082 \n",
      "2024-07-15 20:15:23,027 - INFO - Epoch: 1/5, Iter: 4/93 -- label: 0.0000 loss: 1.7810 \n",
      "2024-07-15 20:15:39,239 - INFO - Epoch: 1/5, Iter: 5/93 -- label: 0.0000 loss: 1.7649 \n",
      "2024-07-15 20:15:54,878 - INFO - Epoch: 1/5, Iter: 6/93 -- label: 5.0000 loss: 1.7462 \n",
      "2024-07-15 20:16:09,905 - INFO - Epoch: 1/5, Iter: 7/93 -- label: 4.0000 loss: 1.7009 \n",
      "2024-07-15 20:16:24,441 - INFO - Epoch: 1/5, Iter: 8/93 -- label: 5.0000 loss: 1.6603 \n",
      "2024-07-15 20:16:39,785 - INFO - Epoch: 1/5, Iter: 9/93 -- label: 2.0000 loss: 1.6386 \n",
      "2024-07-15 20:17:00,248 - INFO - Epoch: 1/5, Iter: 10/93 -- label: 4.0000 loss: 1.6314 \n",
      "2024-07-15 20:17:21,363 - INFO - Epoch: 1/5, Iter: 11/93 -- label: 1.0000 loss: 1.5870 \n",
      "2024-07-15 20:17:43,987 - INFO - Epoch: 1/5, Iter: 12/93 -- label: 1.0000 loss: 1.5494 \n",
      "2024-07-15 20:18:03,355 - INFO - Epoch: 1/5, Iter: 13/93 -- label: 2.0000 loss: 1.5442 \n",
      "2024-07-15 20:18:21,181 - INFO - Epoch: 1/5, Iter: 14/93 -- label: 5.0000 loss: 1.5069 \n",
      "2024-07-15 20:18:38,859 - INFO - Epoch: 1/5, Iter: 15/93 -- label: 1.0000 loss: 1.4981 \n",
      "2024-07-15 20:18:55,598 - INFO - Epoch: 1/5, Iter: 16/93 -- label: 2.0000 loss: 1.4638 \n",
      "2024-07-15 20:19:11,771 - INFO - Epoch: 1/5, Iter: 17/93 -- label: 2.0000 loss: 1.4732 \n",
      "2024-07-15 20:19:28,291 - INFO - Epoch: 1/5, Iter: 18/93 -- label: 2.0000 loss: 1.4127 \n",
      "2024-07-15 20:19:45,337 - INFO - Epoch: 1/5, Iter: 19/93 -- label: 5.0000 loss: 1.3963 \n",
      "2024-07-15 20:20:01,935 - INFO - Epoch: 1/5, Iter: 20/93 -- label: 3.0000 loss: 1.3670 \n",
      "2024-07-15 20:20:19,389 - INFO - Epoch: 1/5, Iter: 21/93 -- label: 0.0000 loss: 1.3707 \n",
      "2024-07-15 20:20:37,490 - INFO - Epoch: 1/5, Iter: 22/93 -- label: 3.0000 loss: 1.3318 \n",
      "2024-07-15 20:20:55,874 - INFO - Epoch: 1/5, Iter: 23/93 -- label: 1.0000 loss: 1.3259 \n",
      "2024-07-15 20:21:13,003 - INFO - Epoch: 1/5, Iter: 24/93 -- label: 1.0000 loss: 1.2923 \n",
      "2024-07-15 20:21:29,602 - INFO - Epoch: 1/5, Iter: 25/93 -- label: 3.0000 loss: 1.2932 \n",
      "2024-07-15 20:21:46,240 - INFO - Epoch: 1/5, Iter: 26/93 -- label: 0.0000 loss: 1.2639 \n",
      "2024-07-15 20:22:03,049 - INFO - Epoch: 1/5, Iter: 27/93 -- label: 1.0000 loss: 1.2315 \n",
      "2024-07-15 20:22:20,216 - INFO - Epoch: 1/5, Iter: 28/93 -- label: 2.0000 loss: 1.2172 \n",
      "2024-07-15 20:22:40,381 - INFO - Epoch: 1/5, Iter: 29/93 -- label: 3.0000 loss: 1.1971 \n",
      "2024-07-15 20:22:57,930 - INFO - Epoch: 1/5, Iter: 30/93 -- label: 4.0000 loss: 1.1776 \n",
      "2024-07-15 20:23:14,599 - INFO - Epoch: 1/5, Iter: 31/93 -- label: 1.0000 loss: 1.1913 \n",
      "2024-07-15 20:23:31,797 - INFO - Epoch: 1/5, Iter: 32/93 -- label: 3.0000 loss: 1.1406 \n",
      "2024-07-15 20:23:48,727 - INFO - Epoch: 1/5, Iter: 33/93 -- label: 1.0000 loss: 1.1357 \n",
      "2024-07-15 20:24:05,727 - INFO - Epoch: 1/5, Iter: 34/93 -- label: 1.0000 loss: 1.1350 \n",
      "2024-07-15 20:24:22,683 - INFO - Epoch: 1/5, Iter: 35/93 -- label: 4.0000 loss: 1.1124 \n",
      "2024-07-15 20:24:40,502 - INFO - Epoch: 1/5, Iter: 36/93 -- label: 4.0000 loss: 1.0830 \n",
      "2024-07-15 20:24:58,464 - INFO - Epoch: 1/5, Iter: 37/93 -- label: 2.0000 loss: 1.0796 \n",
      "2024-07-15 20:25:17,394 - INFO - Epoch: 1/5, Iter: 38/93 -- label: 4.0000 loss: 1.0429 \n",
      "2024-07-15 20:25:35,587 - INFO - Epoch: 1/5, Iter: 39/93 -- label: 4.0000 loss: 1.0553 \n",
      "2024-07-15 20:25:53,677 - INFO - Epoch: 1/5, Iter: 40/93 -- label: 3.0000 loss: 1.0138 \n",
      "2024-07-15 20:26:11,859 - INFO - Epoch: 1/5, Iter: 41/93 -- label: 2.0000 loss: 1.0253 \n",
      "2024-07-15 20:26:30,444 - INFO - Epoch: 1/5, Iter: 42/93 -- label: 4.0000 loss: 0.9834 \n",
      "2024-07-15 20:26:49,133 - INFO - Epoch: 1/5, Iter: 43/93 -- label: 3.0000 loss: 0.9891 \n",
      "2024-07-15 20:27:08,303 - INFO - Epoch: 1/5, Iter: 44/93 -- label: 4.0000 loss: 0.9466 \n",
      "2024-07-15 20:27:26,674 - INFO - Epoch: 1/5, Iter: 45/93 -- label: 2.0000 loss: 0.9573 \n",
      "2024-07-15 20:27:45,078 - INFO - Epoch: 1/5, Iter: 46/93 -- label: 0.0000 loss: 0.9506 \n",
      "2024-07-15 20:28:03,406 - INFO - Epoch: 1/5, Iter: 47/93 -- label: 2.0000 loss: 0.9230 \n",
      "2024-07-15 20:28:21,487 - INFO - Epoch: 1/5, Iter: 48/93 -- label: 3.0000 loss: 0.9123 \n",
      "2024-07-15 20:28:39,844 - INFO - Epoch: 1/5, Iter: 49/93 -- label: 5.0000 loss: 0.9120 \n",
      "2024-07-15 20:28:58,986 - INFO - Epoch: 1/5, Iter: 50/93 -- label: 5.0000 loss: 0.8790 \n",
      "2024-07-15 20:29:18,409 - INFO - Epoch: 1/5, Iter: 51/93 -- label: 5.0000 loss: 0.8690 \n",
      "2024-07-15 20:29:39,478 - INFO - Epoch: 1/5, Iter: 52/93 -- label: 1.0000 loss: 0.8350 \n",
      "2024-07-15 20:29:59,284 - INFO - Epoch: 1/5, Iter: 53/93 -- label: 5.0000 loss: 0.8504 \n",
      "2024-07-15 20:30:18,952 - INFO - Epoch: 1/5, Iter: 54/93 -- label: 4.0000 loss: 0.8401 \n",
      "2024-07-15 20:30:38,862 - INFO - Epoch: 1/5, Iter: 55/93 -- label: 3.0000 loss: 0.8153 \n",
      "2024-07-15 20:30:58,747 - INFO - Epoch: 1/5, Iter: 56/93 -- label: 5.0000 loss: 0.8192 \n",
      "2024-07-15 20:31:18,443 - INFO - Epoch: 1/5, Iter: 57/93 -- label: 3.0000 loss: 0.8059 \n",
      "2024-07-15 20:31:37,951 - INFO - Epoch: 1/5, Iter: 58/93 -- label: 0.0000 loss: 0.7931 \n",
      "2024-07-15 20:31:57,256 - INFO - Epoch: 1/5, Iter: 59/93 -- label: 2.0000 loss: 0.7848 \n",
      "2024-07-15 20:32:16,024 - INFO - Epoch: 1/5, Iter: 60/93 -- label: 5.0000 loss: 0.7924 \n",
      "2024-07-15 20:32:34,733 - INFO - Epoch: 1/5, Iter: 61/93 -- label: 4.0000 loss: 0.7917 \n",
      "2024-07-15 20:33:24,190 - INFO - Epoch: 1/5, Iter: 62/93 -- label: 0.0000 loss: 0.7353 \n",
      "2024-07-15 20:33:40,878 - INFO - Epoch: 1/5, Iter: 63/93 -- label: 2.0000 loss: 0.7576 \n",
      "2024-07-15 20:33:54,770 - INFO - Epoch: 1/5, Iter: 64/93 -- label: 3.0000 loss: 0.6968 \n",
      "2024-07-15 20:34:08,581 - INFO - Epoch: 1/5, Iter: 65/93 -- label: 3.0000 loss: 0.6745 \n",
      "2024-07-15 20:49:39,036 - INFO - Epoch: 1/5, Iter: 66/93 -- label: 1.0000 loss: 0.6810 \n",
      "2024-07-15 20:49:53,475 - INFO - Epoch: 1/5, Iter: 67/93 -- label: 2.0000 loss: 0.6701 \n",
      "2024-07-15 20:50:09,060 - INFO - Epoch: 1/5, Iter: 68/93 -- label: 4.0000 loss: 0.6868 \n",
      "2024-07-15 21:01:42,827 - INFO - Epoch: 1/5, Iter: 69/93 -- label: 4.0000 loss: 0.6615 \n",
      "2024-07-15 21:01:56,386 - INFO - Epoch: 1/5, Iter: 70/93 -- label: 2.0000 loss: 0.6537 \n",
      "2024-07-15 21:02:12,299 - INFO - Epoch: 1/5, Iter: 71/93 -- label: 0.0000 loss: 0.6652 \n",
      "2024-07-15 21:19:20,492 - INFO - Epoch: 1/5, Iter: 72/93 -- label: 5.0000 loss: 0.6156 \n",
      "2024-07-15 21:19:35,970 - INFO - Epoch: 1/5, Iter: 73/93 -- label: 4.0000 loss: 0.6227 \n",
      "2024-07-15 21:19:51,711 - INFO - Epoch: 1/5, Iter: 74/93 -- label: 4.0000 loss: 0.6216 \n",
      "2024-07-15 21:28:56,160 - INFO - Epoch: 1/5, Iter: 75/93 -- label: 3.0000 loss: 0.6266 \n",
      "2024-07-15 21:29:12,933 - INFO - Epoch: 1/5, Iter: 76/93 -- label: 3.0000 loss: 0.6362 \n",
      "2024-07-15 21:29:28,878 - INFO - Epoch: 1/5, Iter: 77/93 -- label: 0.0000 loss: 0.6221 \n",
      "2024-07-15 21:29:44,369 - INFO - Epoch: 1/5, Iter: 78/93 -- label: 3.0000 loss: 0.5528 \n",
      "2024-07-15 21:29:58,144 - INFO - Epoch: 1/5, Iter: 79/93 -- label: 1.0000 loss: 0.5600 \n",
      "2024-07-15 21:30:12,097 - INFO - Epoch: 1/5, Iter: 80/93 -- label: 2.0000 loss: 0.5553 \n",
      "2024-07-15 21:30:27,454 - INFO - Epoch: 1/5, Iter: 81/93 -- label: 4.0000 loss: 0.5313 \n",
      "2024-07-15 21:30:41,599 - INFO - Epoch: 1/5, Iter: 82/93 -- label: 3.0000 loss: 0.5513 \n",
      "2024-07-15 21:30:56,104 - INFO - Epoch: 1/5, Iter: 83/93 -- label: 1.0000 loss: 0.5156 \n",
      "2024-07-15 21:31:10,986 - INFO - Epoch: 1/5, Iter: 84/93 -- label: 3.0000 loss: 0.5550 \n",
      "2024-07-15 21:31:29,369 - INFO - Epoch: 1/5, Iter: 85/93 -- label: 0.0000 loss: 0.5427 \n",
      "2024-07-15 21:31:45,024 - INFO - Epoch: 1/5, Iter: 86/93 -- label: 2.0000 loss: 0.5399 \n",
      "2024-07-15 21:32:01,897 - INFO - Epoch: 1/5, Iter: 87/93 -- label: 0.0000 loss: 0.5207 \n",
      "2024-07-15 21:32:17,536 - INFO - Epoch: 1/5, Iter: 88/93 -- label: 4.0000 loss: 0.4878 \n",
      "2024-07-15 21:32:33,754 - INFO - Epoch: 1/5, Iter: 89/93 -- label: 1.0000 loss: 0.4889 \n",
      "2024-07-15 21:32:49,546 - INFO - Epoch: 1/5, Iter: 90/93 -- label: 0.0000 loss: 0.4829 \n",
      "2024-07-15 21:33:05,916 - INFO - Epoch: 1/5, Iter: 91/93 -- label: 5.0000 loss: 0.4946 \n",
      "2024-07-15 21:33:31,066 - INFO - Epoch: 1/5, Iter: 92/93 -- label: 5.0000 loss: 0.4651 \n",
      "2024-07-15 21:33:33,874 - INFO - Epoch: 1/5, Iter: 93/93 -- label: 4.0000 loss: 0.5488 \n",
      "INFO:ignite.engine.engine.SupervisedTrainer:Epoch[1] Complete. Time taken: 01:19:12.308\n",
      "2024-07-15 21:33:55,121 - INFO - Epoch: 2/5, Iter: 1/93 -- label: 3.0000 loss: 0.4591 \n",
      "2024-07-15 21:34:15,318 - INFO - Epoch: 2/5, Iter: 2/93 -- label: 5.0000 loss: 0.4499 \n",
      "2024-07-15 21:34:35,700 - INFO - Epoch: 2/5, Iter: 3/93 -- label: 1.0000 loss: 0.4489 \n",
      "2024-07-15 21:34:55,124 - INFO - Epoch: 2/5, Iter: 4/93 -- label: 3.0000 loss: 0.4582 \n",
      "2024-07-15 21:35:14,581 - INFO - Epoch: 2/5, Iter: 5/93 -- label: 3.0000 loss: 0.4218 \n",
      "2024-07-15 21:35:34,713 - INFO - Epoch: 2/5, Iter: 6/93 -- label: 4.0000 loss: 0.4169 \n",
      "2024-07-15 21:35:56,492 - INFO - Epoch: 2/5, Iter: 7/93 -- label: 0.0000 loss: 0.4288 \n",
      "2024-07-15 21:36:15,853 - INFO - Epoch: 2/5, Iter: 8/93 -- label: 0.0000 loss: 0.4014 \n",
      "2024-07-15 21:36:33,340 - INFO - Epoch: 2/5, Iter: 9/93 -- label: 5.0000 loss: 0.3865 \n",
      "2024-07-15 21:36:52,200 - INFO - Epoch: 2/5, Iter: 10/93 -- label: 3.0000 loss: 0.3968 \n",
      "2024-07-15 21:37:10,716 - INFO - Epoch: 2/5, Iter: 11/93 -- label: 3.0000 loss: 0.3933 \n",
      "2024-07-15 21:37:27,076 - INFO - Epoch: 2/5, Iter: 12/93 -- label: 1.0000 loss: 0.3909 \n",
      "2024-07-15 21:37:42,960 - INFO - Epoch: 2/5, Iter: 13/93 -- label: 0.0000 loss: 0.3889 \n",
      "2024-07-15 21:37:58,334 - INFO - Epoch: 2/5, Iter: 14/93 -- label: 4.0000 loss: 0.3494 \n",
      "2024-07-15 21:38:13,767 - INFO - Epoch: 2/5, Iter: 15/93 -- label: 2.0000 loss: 0.3752 \n",
      "2024-07-15 21:38:29,410 - INFO - Epoch: 2/5, Iter: 16/93 -- label: 3.0000 loss: 0.3540 \n",
      "2024-07-15 21:38:44,494 - INFO - Epoch: 2/5, Iter: 17/93 -- label: 1.0000 loss: 0.3804 \n",
      "2024-07-15 21:39:00,389 - INFO - Epoch: 2/5, Iter: 18/93 -- label: 2.0000 loss: 0.3576 \n",
      "2024-07-15 21:39:16,530 - INFO - Epoch: 2/5, Iter: 19/93 -- label: 1.0000 loss: 0.3707 \n",
      "2024-07-15 21:39:32,003 - INFO - Epoch: 2/5, Iter: 20/93 -- label: 5.0000 loss: 0.3399 \n",
      "2024-07-15 21:39:47,333 - INFO - Epoch: 2/5, Iter: 21/93 -- label: 2.0000 loss: 0.3501 \n",
      "2024-07-15 21:40:03,186 - INFO - Epoch: 2/5, Iter: 22/93 -- label: 1.0000 loss: 0.3410 \n",
      "2024-07-15 21:40:19,391 - INFO - Epoch: 2/5, Iter: 23/93 -- label: 2.0000 loss: 0.3336 \n",
      "2024-07-15 21:40:36,883 - INFO - Epoch: 2/5, Iter: 24/93 -- label: 0.0000 loss: 0.3328 \n",
      "2024-07-15 21:40:52,739 - INFO - Epoch: 2/5, Iter: 25/93 -- label: 2.0000 loss: 0.3153 \n",
      "2024-07-15 21:41:08,736 - INFO - Epoch: 2/5, Iter: 26/93 -- label: 3.0000 loss: 0.3003 \n",
      "2024-07-15 21:41:24,476 - INFO - Epoch: 2/5, Iter: 27/93 -- label: 1.0000 loss: 0.3193 \n",
      "2024-07-15 21:41:40,191 - INFO - Epoch: 2/5, Iter: 28/93 -- label: 0.0000 loss: 0.3309 \n",
      "2024-07-15 21:41:55,631 - INFO - Epoch: 2/5, Iter: 29/93 -- label: 3.0000 loss: 0.3200 \n",
      "2024-07-15 21:42:11,389 - INFO - Epoch: 2/5, Iter: 30/93 -- label: 1.0000 loss: 0.2973 \n",
      "2024-07-15 21:42:26,943 - INFO - Epoch: 2/5, Iter: 31/93 -- label: 0.0000 loss: 0.3229 \n",
      "2024-07-15 21:42:42,656 - INFO - Epoch: 2/5, Iter: 32/93 -- label: 4.0000 loss: 0.2891 \n",
      "2024-07-15 21:42:58,521 - INFO - Epoch: 2/5, Iter: 33/93 -- label: 5.0000 loss: 0.3111 \n",
      "2024-07-15 21:43:14,629 - INFO - Epoch: 2/5, Iter: 34/93 -- label: 4.0000 loss: 0.3303 \n",
      "2024-07-15 21:43:31,600 - INFO - Epoch: 2/5, Iter: 35/93 -- label: 0.0000 loss: 0.2963 \n",
      "2024-07-15 21:43:48,283 - INFO - Epoch: 2/5, Iter: 36/93 -- label: 3.0000 loss: 0.2924 \n",
      "2024-07-15 21:44:06,325 - INFO - Epoch: 2/5, Iter: 37/93 -- label: 0.0000 loss: 0.2747 \n",
      "2024-07-15 21:44:24,447 - INFO - Epoch: 2/5, Iter: 38/93 -- label: 5.0000 loss: 0.2740 \n",
      "2024-07-15 21:44:41,746 - INFO - Epoch: 2/5, Iter: 39/93 -- label: 2.0000 loss: 0.2957 \n",
      "2024-07-15 21:44:59,273 - INFO - Epoch: 2/5, Iter: 40/93 -- label: 2.0000 loss: 0.2754 \n",
      "2024-07-15 21:45:17,333 - INFO - Epoch: 2/5, Iter: 41/93 -- label: 3.0000 loss: 0.2809 \n",
      "2024-07-15 21:45:35,248 - INFO - Epoch: 2/5, Iter: 42/93 -- label: 0.0000 loss: 0.2563 \n",
      "2024-07-15 21:45:55,019 - INFO - Epoch: 2/5, Iter: 43/93 -- label: 1.0000 loss: 0.2663 \n",
      "2024-07-15 21:46:14,445 - INFO - Epoch: 2/5, Iter: 44/93 -- label: 3.0000 loss: 0.2714 \n",
      "2024-07-15 21:46:34,230 - INFO - Epoch: 2/5, Iter: 45/93 -- label: 4.0000 loss: 0.2715 \n",
      "2024-07-15 21:46:53,749 - INFO - Epoch: 2/5, Iter: 46/93 -- label: 5.0000 loss: 0.2798 \n",
      "2024-07-15 21:47:14,077 - INFO - Epoch: 2/5, Iter: 47/93 -- label: 0.0000 loss: 0.2232 \n",
      "2024-07-15 21:47:33,562 - INFO - Epoch: 2/5, Iter: 48/93 -- label: 5.0000 loss: 0.2633 \n",
      "2024-07-15 21:47:52,765 - INFO - Epoch: 2/5, Iter: 49/93 -- label: 2.0000 loss: 0.2627 \n",
      "2024-07-15 21:48:12,666 - INFO - Epoch: 2/5, Iter: 50/93 -- label: 0.0000 loss: 0.2682 \n",
      "2024-07-15 21:48:32,832 - INFO - Epoch: 2/5, Iter: 51/93 -- label: 1.0000 loss: 0.2274 \n",
      "2024-07-15 21:48:52,260 - INFO - Epoch: 2/5, Iter: 52/93 -- label: 5.0000 loss: 0.2621 \n",
      "2024-07-15 21:49:12,445 - INFO - Epoch: 2/5, Iter: 53/93 -- label: 4.0000 loss: 0.2605 \n",
      "2024-07-15 21:49:32,707 - INFO - Epoch: 2/5, Iter: 54/93 -- label: 2.0000 loss: 0.2477 \n",
      "2024-07-15 21:49:52,585 - INFO - Epoch: 2/5, Iter: 55/93 -- label: 5.0000 loss: 0.2460 \n",
      "2024-07-15 21:50:13,502 - INFO - Epoch: 2/5, Iter: 56/93 -- label: 1.0000 loss: 0.2277 \n",
      "2024-07-15 21:50:34,742 - INFO - Epoch: 2/5, Iter: 57/93 -- label: 2.0000 loss: 0.2426 \n",
      "2024-07-15 21:50:58,120 - INFO - Epoch: 2/5, Iter: 58/93 -- label: 5.0000 loss: 0.2286 \n",
      "2024-07-15 21:51:12,482 - INFO - Epoch: 2/5, Iter: 59/93 -- label: 5.0000 loss: 0.2371 \n",
      "2024-07-15 21:51:28,550 - INFO - Epoch: 2/5, Iter: 60/93 -- label: 0.0000 loss: 0.2411 \n",
      "2024-07-15 21:56:54,307 - INFO - Epoch: 2/5, Iter: 61/93 -- label: 2.0000 loss: 0.2235 \n",
      "2024-07-15 21:57:10,304 - INFO - Epoch: 2/5, Iter: 62/93 -- label: 1.0000 loss: 0.2533 \n",
      "2024-07-15 21:57:25,024 - INFO - Epoch: 2/5, Iter: 63/93 -- label: 5.0000 loss: 0.2194 \n",
      "2024-07-15 21:57:39,070 - INFO - Epoch: 2/5, Iter: 64/93 -- label: 0.0000 loss: 0.2132 \n",
      "2024-07-15 21:57:55,333 - INFO - Epoch: 2/5, Iter: 65/93 -- label: 5.0000 loss: 0.2136 \n",
      "2024-07-15 21:58:10,144 - INFO - Epoch: 2/5, Iter: 66/93 -- label: 1.0000 loss: 0.2220 \n",
      "2024-07-15 21:58:29,461 - INFO - Epoch: 2/5, Iter: 67/93 -- label: 5.0000 loss: 0.2024 \n",
      "2024-07-15 21:58:49,262 - INFO - Epoch: 2/5, Iter: 68/93 -- label: 5.0000 loss: 0.1932 \n",
      "2024-07-15 21:59:21,341 - INFO - Epoch: 2/5, Iter: 69/93 -- label: 1.0000 loss: 0.2188 \n",
      "2024-07-15 22:00:00,444 - INFO - Epoch: 2/5, Iter: 70/93 -- label: 1.0000 loss: 0.2093 \n",
      "2024-07-15 22:00:32,587 - INFO - Epoch: 2/5, Iter: 71/93 -- label: 2.0000 loss: 0.1832 \n",
      "2024-07-15 22:01:01,534 - INFO - Epoch: 2/5, Iter: 72/93 -- label: 1.0000 loss: 0.1915 \n",
      "2024-07-15 22:01:33,244 - INFO - Epoch: 2/5, Iter: 73/93 -- label: 5.0000 loss: 0.1828 \n",
      "2024-07-15 22:02:00,405 - INFO - Epoch: 2/5, Iter: 74/93 -- label: 1.0000 loss: 0.2118 \n",
      "2024-07-15 22:02:31,900 - INFO - Epoch: 2/5, Iter: 75/93 -- label: 3.0000 loss: 0.2297 \n",
      "2024-07-15 22:03:09,960 - INFO - Epoch: 2/5, Iter: 76/93 -- label: 2.0000 loss: 0.1952 \n",
      "2024-07-15 22:03:36,415 - INFO - Epoch: 2/5, Iter: 77/93 -- label: 3.0000 loss: 0.1955 \n",
      "2024-07-15 22:04:09,442 - INFO - Epoch: 2/5, Iter: 78/93 -- label: 0.0000 loss: 0.2036 \n",
      "2024-07-15 22:04:43,435 - INFO - Epoch: 2/5, Iter: 79/93 -- label: 5.0000 loss: 0.2150 \n",
      "2024-07-15 22:05:13,777 - INFO - Epoch: 2/5, Iter: 80/93 -- label: 4.0000 loss: 0.2006 \n",
      "2024-07-15 22:05:46,752 - INFO - Epoch: 2/5, Iter: 81/93 -- label: 3.0000 loss: 0.1851 \n",
      "2024-07-15 22:06:18,483 - INFO - Epoch: 2/5, Iter: 82/93 -- label: 4.0000 loss: 0.1759 \n",
      "2024-07-15 22:06:45,628 - INFO - Epoch: 2/5, Iter: 83/93 -- label: 3.0000 loss: 0.1946 \n",
      "2024-07-15 22:07:13,094 - INFO - Epoch: 2/5, Iter: 84/93 -- label: 3.0000 loss: 0.1789 \n",
      "2024-07-15 22:07:38,886 - INFO - Epoch: 2/5, Iter: 85/93 -- label: 4.0000 loss: 0.1845 \n",
      "2024-07-15 22:08:04,273 - INFO - Epoch: 2/5, Iter: 86/93 -- label: 4.0000 loss: 0.1805 \n",
      "2024-07-15 22:08:30,219 - INFO - Epoch: 2/5, Iter: 87/93 -- label: 1.0000 loss: 0.1837 \n",
      "2024-07-15 22:08:57,751 - INFO - Epoch: 2/5, Iter: 88/93 -- label: 4.0000 loss: 0.1967 \n",
      "2024-07-15 22:09:31,596 - INFO - Epoch: 2/5, Iter: 89/93 -- label: 3.0000 loss: 0.1884 \n",
      "2024-07-15 22:10:02,055 - INFO - Epoch: 2/5, Iter: 90/93 -- label: 1.0000 loss: 0.1861 \n",
      "2024-07-15 22:10:30,567 - INFO - Epoch: 2/5, Iter: 91/93 -- label: 3.0000 loss: 0.1640 \n",
      "2024-07-15 22:11:02,315 - INFO - Epoch: 2/5, Iter: 92/93 -- label: 0.0000 loss: 0.1640 \n",
      "2024-07-15 22:11:06,669 - INFO - Epoch: 2/5, Iter: 93/93 -- label: 1.0000 loss: 0.2333 \n",
      "INFO:ignite.engine.engine.SupervisedTrainer:Epoch[2] Complete. Time taken: 00:37:32.790\n",
      "ERROR:ignite.engine.engine.SupervisedTrainer:Engine run is terminating due to exception: \n",
      "2024-07-15 22:11:18,448 - ERROR - Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py\", line 956, in _internal_run_as_gen\n",
      "    epoch_time_taken += yield from self._run_once_on_dataset_as_gen()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py\", line 1077, in _run_once_on_dataset_as_gen\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/engines/trainer.py\", line 265, in _iteration\n",
      "    _compute_pred_loss()\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/engines/trainer.py\", line 249, in _compute_pred_loss\n",
      "    engine.state.output[Keys.PRED] = engine.inferer(inputs, engine.network, *args, **kwargs)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/inferers/inferer.py\", line 379, in __call__\n",
      "    return network(inputs, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/networks/nets/densenet.py\", line 254, in forward\n",
      "    x = self.features(x)\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/networks/nets/densenet.py\", line 87, in forward\n",
      "    new_features = self.layers(x)\n",
      "                   ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/data/meta_tensor.py\", line 282, in __torch_function__\n",
      "    ret = super().__torch_function__(func, types, args, kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/_tensor.py\", line 1443, in __torch_function__\n",
      "    ret = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/engines/trainer.py:56\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mExecute training based on Ignite Engine.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03mIf call this function multiple times, it will continuously run from the previous state.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mGradScaler() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/engines/workflow.py:283\u001b[0m, in \u001b[0;36mWorkflow.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dataloader` is empty or the specified `epoch_length` is 0, skip the `run`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m If running distributed training, the program may hang in `all-gather`, `all-reduce`, etc.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because not all the ranks run the same computation logic.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmax_epochs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run()\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(e)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:642\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_exception\u001b[39m(\u001b[38;5;28mself\u001b[39m, e: \u001b[38;5;167;01mBaseException\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_handlers:\n\u001b[0;32m--> 642\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:431\u001b[0m, in \u001b[0;36mEngine._fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(event_kwargs)\n\u001b[1;32m    430\u001b[0m first, others \u001b[38;5;241m=\u001b[39m ((args[\u001b[38;5;241m0\u001b[39m],), args[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mif\u001b[39;00m (args \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m ((), args)\n\u001b[0;32m--> 431\u001b[0m func(\u001b[38;5;241m*\u001b[39mfirst, \u001b[38;5;241m*\u001b[39m(event_args \u001b[38;5;241m+\u001b[39m others), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/handlers/stats_handler.py:202\u001b[0m, in \u001b[0;36mStatsHandler.exception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03mHandler for train or validation/evaluation exception raised Event.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03mPrint the exception information and traceback. This callback may be skipped because the logic\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/ignite/engine/engine.py:1077\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_function(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/engines/trainer.py:265\u001b[0m, in \u001b[0;36mSupervisedTrainer._iteration\u001b[0;34m(self, engine, batchdata)\u001b[0m\n\u001b[1;32m    263\u001b[0m     engine\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     _compute_pred_loss()\n\u001b[1;32m    266\u001b[0m     engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mLOSS]\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    267\u001b[0m     engine\u001b[38;5;241m.\u001b[39mfire_event(IterationEvents\u001b[38;5;241m.\u001b[39mBACKWARD_COMPLETED)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/engines/trainer.py:249\u001b[0m, in \u001b[0;36mSupervisedTrainer._iteration.<locals>._compute_pred_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_pred_loss\u001b[39m():\n\u001b[0;32m--> 249\u001b[0m     engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mPRED] \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39minferer(inputs, engine\u001b[38;5;241m.\u001b[39mnetwork, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    250\u001b[0m     engine\u001b[38;5;241m.\u001b[39mfire_event(IterationEvents\u001b[38;5;241m.\u001b[39mFORWARD_COMPLETED)\n\u001b[1;32m    251\u001b[0m     engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mLOSS] \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mloss_function(engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mPRED], targets)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/inferers/inferer.py:379\u001b[0m, in \u001b[0;36mSimpleInferer.__call__\u001b[0;34m(self, inputs, network, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs: torch\u001b[38;5;241m.\u001b[39mTensor, network: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Unified callable function API of Inferers.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m network(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/networks/nets/densenet.py:254\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 254\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    255\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_layers(x)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/networks/nets/densenet.py:87\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 87\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([x, new_features], \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/monai/data/meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__torch_function__(func, types, args, kwargs)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/monai/lib/python3.12/site-packages/torch/_tensor.py:1443\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1443\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the prediction on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(root_dir, \"MedNIST\")\n",
    "class_names = sorted(f\"{x.name}\" for x in dataset_dir.iterdir() if x.is_dir())\n",
    "testdata = MedNISTDataset(root_dir=root_dir, transform=transform, section=\"test\", download=False, runtime_cache=True)\n",
    "\n",
    "max_items_to_print = 10\n",
    "with eval_mode(model):\n",
    "    for item in DataLoader(testdata, batch_size=1):\n",
    "        prob = np.array(model(item[\"image\"].to(\"cpu\")).detach().to(\"cpu\"))[0]\n",
    "        pred = class_names[prob.argmax()]\n",
    "        gt = item[\"class_name\"][0]\n",
    "        print(f\"Class prediction is {pred}. Ground-truth: {gt}\")\n",
    "        max_items_to_print -= 1\n",
    "        if max_items_to_print == 0:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
